[general]
# Database folder
# If no base_dir is given, the default base_dir will be used instead
#base_dir = ...
base_dir = /work3/s212656/datasets
#/zhome/06/a/164758/Documents/thesis/Thesis_code/segmappy/training_datasets
cnn_train_folders = g_train,t_train,t_test,dataset18
cnn_test_folder = t_train
#cnn_roc_folder = g_train2
semantics_train_folder = t_test

# Combine sequences based on merge events triggered in segmatch
use_merges = false

# Size of the merged sequence compared to the last element in the merged
# sequence to keep matches containing the merged sequence
keep_match_thresh = 0.3

# Combine the views based on the segmatch matches
use_matches = false

# Discard classes of segments that are smaller than min_class_size
min_class_size = 0

# The relative size of a segment compared to the last segment in the sequence
# so that it is still considered relevant and kept
require_relevance = 0.05

# The number of points that must be different so that two segments are
# considered different. Similar segments are removed in chronological order
require_diff_points = 0

[augment]
# Generate new samples by randomly rotating each sample by
# [-augment_angle, augment_angle] degrees.
augment_angle = 180
#180

# Augment by randomly removing a percentage of points from each sample
augment_remove_random_min = 0.0
augment_remove_random_max = 0.1
augment_remove_plane_min = 0.0
augment_remove_plane_max = 0.5

# Augment by randomly jittering the segment after centering
augment_jitter = 0.0

[normalize]
# Align the segments (robot/eigen/none)
align = eigen
#eigen

# Which type of scaling to use
#     - fixed: use a fixed scale
#     - aspect: scale, but maintain aspect ratio
#     - fit: scale each dimenstion indipendently
scale_method = fit

# How to center the segment
#     - mean: based on the segments mean, some point will be out of bounds
#     - min_max: centers based on the min and max of each dimension
#     - none: no centering
center_method = mean

# Size of the voxel parallelepiped in meters
scale_x = 8
scale_y = 8
scale_z = 4

# Number of voxels in the rectangular parallelepiped into
# which to normalize each segment
voxels_x = 32
voxels_y = 32
voxels_z = 16
#/2
# Remove the mean and std
remove_mean = false
remove_std = false

[train]
# Folder into which to save the model after training
# If no model_base_dir is given, the default model_base_dir will be used instead
#model_base_dir = ...
model_base_dir = /work3/s212656/segmappy/trained_models_v4
cnn_model_folder = segmap64_haoranDrone
semantics_model_folder = segmap64_semantics

# Percentage of match sequences to put in the test set
test_size = 0.3

# Number of epochs to train for
n_epochs = 500

#256
# Batch size
batch_size = 64
# 64

# Root path to save tensorboard logs
log_path = /work3/s212656/segmappy/tensorboard

# Directory where to save debug outputs
debug_path = /work3/s212656/segmappy/debug
